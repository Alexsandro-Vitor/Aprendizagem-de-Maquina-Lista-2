{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código Learning Vector Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Suporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [[1, 0], [2, 0]], 1: [[1, 1]], 2: [[2, 2]]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 0], [1, 1], [2, 2], [2, 0]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_prototypes(dataset, n_prototypes = 2):\n",
    "    '''Choose a number of samples from the dataset to use as prototypes. Will keep at least one sample of every class.'''\n",
    "    classes = {x[-1]: [a for a in dataset if a[-1] == x[-1]] for x in dataset}\n",
    "    print(classes)\n",
    "        \n",
    "    if (n_prototypes < len(classes)):\n",
    "        print(\"There aren't prototypes enough for all classes\")\n",
    "    elif (n_prototypes > len(dataset)):\n",
    "        print(\"There aren't samples enough for this amount of prototypes\")\n",
    "    else:\n",
    "        prototypes = [random.choice(classes[x]) for x in classes]\n",
    "        if (n_prototypes > len(classes)):\n",
    "            still_not_chosen = [data for data in dataset if data not in prototypes]\n",
    "            prototypes.extend(random.sample(still_not_chosen, n_prototypes - len(classes)))\n",
    "        return prototypes\n",
    "\n",
    "sample_prototypes([[1, 0],[1, 1],[2, 2],[2, 0]], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_results(real, predicted):\n",
    "    matched = [a == b for (a, b) in zip(real, predicted)]\n",
    "    recalls = {i: list(zip(real, matched)).count((i, True)) / real.count(i) for i in real}\n",
    "    return {\n",
    "        \"precision\": matched.count(True) / len(real),\n",
    "        \"recalls\": recalls\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código do LVQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LVQ1:\n",
    "    def __init__(self, k = 1, n_prototypes = 2, alpha_0 = 0.8):\n",
    "        self.knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        self.n_prototypes = n_prototypes\n",
    "        self.alpha_0 = alpha_0\n",
    "    \n",
    "    def adjust_prototype(self, prototype_index, alpha, sample):\n",
    "        prototype = self.samples[prototype_index]\n",
    "        if (self.labels[prototype_index] == sample[-1]):\n",
    "            self.samples[prototype_index] = prototype + (sample[0:-1] - prototype) * alpha\n",
    "        else:\n",
    "            self.samples[prototype_index] = prototype - (sample[0:-1] - prototype) * alpha\n",
    "        print(prototype_index)\n",
    "        print(self.samples[prototype_index])\n",
    "    \n",
    "    def train(self, training):\n",
    "        prototypes = sample_prototypes(training, self.n_prototypes)\n",
    "        print(prototypes)\n",
    "        self.samples = [sample[0:-1] for sample in prototypes]\n",
    "        self.labels = [sample[-1] for sample in prototypes]\n",
    "        \n",
    "        alpha_t = self.alpha_0\n",
    "        for sample in training:\n",
    "            self.knn.fit(self.samples, self.labels)\n",
    "            (_, closest) = self.knn.kneighbors([sample[0:-1]])\n",
    "            [self.adjust_prototype(prototype_index, alpha_t, sample) for prototype_index in closest[0]]\n",
    "            alpha_t *= self.alpha_0\n",
    "        \n",
    "        self.knn.fit(self.samples, self.labels)\n",
    "    \n",
    "    def predict(self, sample):\n",
    "        return self.knn.predict(sample)\n",
    "    \n",
    "    def test(self, testing):\n",
    "        samples = [sample[0:-1] for sample in testing]\n",
    "        labels = [sample[-1] for sample in testing]\n",
    "        print(labels)\n",
    "        predicted_labels = self.predict(samples)\n",
    "        print(predicted_labels)\n",
    "        result = calculate_test_results(labels, predicted_labels)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [array([1, 0, 0]), array([2, 1, 0])], 1: [array([1, 1, 1])], 2: [array([2, 0, 2])]}\n",
      "[array([1, 0, 0]), array([1, 1, 1]), array([2, 0, 2])]\n",
      "0\n",
      "[1. 0.]\n",
      "1\n",
      "[1. 1.]\n",
      "2\n",
      "[2. 0.]\n",
      "1\n",
      "[0.5904 1.    ]\n",
      "[1, 0]\n",
      "[1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 1.0, 'recalls': {1: 1.0, 0: 1.0}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvq1 = LVQ1(n_prototypes=3)\n",
    "lvq1.train(np.array([[1,0,0], [1,1,1], [2,0,2], [2,1,0]]))\n",
    "lvq1.test([[0, 1, 1], [1, 0.2, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código do LVQ2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LVQ2:\n",
    "    def __init__(self, k = 1, nPrototypes = 2):\n",
    "        self.knn = NearestNeighbors(n_neighbors = k)\n",
    "        self.nPrototypes = nPrototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código do LVQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LVQ3:\n",
    "    def __init__(self, k = 1, nPrototypes = 2):\n",
    "        self.knn = NearestNeighbors(n_neighbors = k)\n",
    "        self.nPrototypes = nPrototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from time import process_time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para o experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(raw):\n",
    "    '''Normalizes an dataset so all of its attributes have the same weight.'''\n",
    "    attribute_mins = np.min(raw, axis=0)\n",
    "    attribute_maxs = np.max(raw, axis=0)\n",
    "    return (raw - attribute_mins) / attribute_maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(sep_samples, k = 5):\n",
    "    ''''Splits the samples in k groups with similar amounts of samples and distributions of every class.'''\n",
    "    folds = [[] for _ in range(k)]\n",
    "    for i in sep_samples:\n",
    "        split_class = np.array_split(sep_samples[i], k)\n",
    "        [a.extend(b) for (a, b) in zip(folds, split_class)]\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(machine, folds):\n",
    "    '''Evaluates an algorithm through cross validation.'''\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    train_times = []\n",
    "    test_times = []\n",
    "    for i in range(len(folds)):\n",
    "        print(\"Testing on fold \" + str(i))\n",
    "        train = [s for j, fold in enumerate(folds) if i != j for s in fold]\n",
    "        test = folds[i]\n",
    "\n",
    "        train_times.append(process_time())\n",
    "        machine.train(train)\n",
    "        train_times[-1] = process_time() - train_times[-1]\n",
    "\n",
    "        test_times.append(process_time())\n",
    "        test_results = machine.test(test)\n",
    "        test_times[-1] = process_time() - test_times[-1]\n",
    "\n",
    "        precisions.append(test_results['precision'])\n",
    "        recalls.append(test_results['recalls'])\n",
    "    return {'precisions': precisions, 'recalls': recalls, 'train_times': train_times, 'test_times': test_times}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de Dados 1 - CM1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.1,   1.4,   1.4, ...,   1.2,   1.4,   0. ],\n",
       "       [  1. ,   1. ,   1. , ...,   1. ,   1. ,   1. ],\n",
       "       [ 24. ,   5. ,   1. , ...,  19. ,   9. ,   0. ],\n",
       "       ...,\n",
       "       [ 82. ,  11. ,   3. , ..., 190. ,  21. ,   1. ],\n",
       "       [ 10. ,   2. ,   1. , ...,  13. ,   3. ,   1. ],\n",
       "       [ 28. ,   6. ,   5. , ...,  37. ,  11. ,   1. ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = arff.loadarff('Datasets/cm1.arff')\n",
    "dataFrame = pd.DataFrame(data[0])\n",
    "dataFrame.defects = [1 if i == b'true' else 0 for i in dataFrame.defects]\n",
    "rawData = dataFrame.values\n",
    "rawData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.36406619e-04, 4.16666667e-03, 1.33333333e-02, ...,\n",
       "        1.47420147e-03, 2.46913580e-03, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        1.22850123e-03, 0.00000000e+00, 1.00000000e+00],\n",
       "       [5.43735225e-02, 4.16666667e-02, 0.00000000e+00, ...,\n",
       "        2.33415233e-02, 4.93827160e-02, 0.00000000e+00],\n",
       "       ...,\n",
       "       [1.91489362e-01, 1.04166667e-01, 6.66666667e-02, ...,\n",
       "        2.33415233e-01, 1.23456790e-01, 1.00000000e+00],\n",
       "       [2.12765957e-02, 1.04166667e-02, 0.00000000e+00, ...,\n",
       "        1.59705160e-02, 1.23456790e-02, 1.00000000e+00],\n",
       "       [6.38297872e-02, 5.20833333e-02, 1.33333333e-01, ...,\n",
       "        4.54545455e-02, 6.17283951e-02, 1.00000000e+00]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing the dataset\n",
    "normalizedData = normalize(rawData)\n",
    "normalizedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: array([[0.00023641, 0.00416667, 0.01333333, ..., 0.0014742 , 0.00246914,\n",
       "         0.        ],\n",
       "        [0.05437352, 0.04166667, 0.        , ..., 0.02334152, 0.04938272,\n",
       "         0.        ],\n",
       "        [0.04491726, 0.03125   , 0.1       , ..., 0.01965602, 0.03703704,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.0070922 , 0.        , 0.        , ..., 0.00737101, 0.        ,\n",
       "         0.        ],\n",
       "        [0.00472813, 0.        , 0.        , ..., 0.002457  , 0.        ,\n",
       "         0.        ],\n",
       "        [0.02600473, 0.02083333, 0.        , ..., 0.03071253, 0.02469136,\n",
       "         0.        ]]),\n",
       " 1.0: array([[0.        , 0.        , 0.        , ..., 0.0012285 , 0.        ,\n",
       "         1.        ],\n",
       "        [0.07092199, 0.03125   , 0.        , ..., 0.06265356, 0.03703704,\n",
       "         1.        ],\n",
       "        [0.06619385, 0.04166667, 0.        , ..., 0.04545455, 0.04938272,\n",
       "         1.        ],\n",
       "        ...,\n",
       "        [0.19148936, 0.10416667, 0.06666667, ..., 0.23341523, 0.12345679,\n",
       "         1.        ],\n",
       "        [0.0212766 , 0.01041667, 0.        , ..., 0.01597052, 0.01234568,\n",
       "         1.        ],\n",
       "        [0.06382979, 0.05208333, 0.13333333, ..., 0.04545455, 0.0617284 ,\n",
       "         1.        ]])}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating samples by class\n",
    "classes = {i[-1]: normalizedData[np.where(rawData[:,-1] == i[-1])] for i in normalizedData}\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 100, 100, 100, 98]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating the folds\n",
    "folds = k_fold(classes)\n",
    "[len(fold) for fold in folds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução do KNN básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução do LVQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução do LVQ2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução do LVQ3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de Dados 2 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redesNeurais",
   "language": "python",
   "name": "redesneurais"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
